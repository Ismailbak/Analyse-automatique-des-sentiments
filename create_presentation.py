"""
Script to create a professional PowerPoint presentation
for the Sentiment Analysis project
"""

from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.enum.text import PP_ALIGN
from pptx.dml.color import RGBColor
import pandas as pd
from pathlib import Path

# Create presentation
prs = Presentation()
prs.slide_width = Inches(10)
prs.slide_height = Inches(7.5)

def add_title_slide(prs, title, subtitle):
    """Add a title slide"""
    slide = prs.slides.add_slide(prs.slide_layouts[6])  # Blank layout
    
    # Add title
    title_box = slide.shapes.add_textbox(Inches(0.5), Inches(2.5), Inches(9), Inches(1))
    title_frame = title_box.text_frame
    title_frame.text = title
    title_frame.paragraphs[0].font.size = Pt(44)
    title_frame.paragraphs[0].font.bold = True
    title_frame.paragraphs[0].font.color.rgb = RGBColor(31, 78, 121)
    title_frame.paragraphs[0].alignment = PP_ALIGN.CENTER
    
    # Add subtitle
    subtitle_box = slide.shapes.add_textbox(Inches(0.5), Inches(4), Inches(9), Inches(0.8))
    subtitle_frame = subtitle_box.text_frame
    subtitle_frame.text = subtitle
    subtitle_frame.paragraphs[0].font.size = Pt(24)
    subtitle_frame.paragraphs[0].alignment = PP_ALIGN.CENTER
    
    return slide

def add_content_slide(prs, title, content_items):
    """Add a content slide with bullet points"""
    slide = prs.slides.add_slide(prs.slide_layouts[6])
    
    # Add title
    title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.5), Inches(9), Inches(0.8))
    title_frame = title_box.text_frame
    title_frame.text = title
    title_frame.paragraphs[0].font.size = Pt(32)
    title_frame.paragraphs[0].font.bold = True
    title_frame.paragraphs[0].font.color.rgb = RGBColor(31, 78, 121)
    
    # Add content
    content_box = slide.shapes.add_textbox(Inches(0.8), Inches(1.8), Inches(8.4), Inches(5))
    text_frame = content_box.text_frame
    
    for item in content_items:
        p = text_frame.add_paragraph()
        p.text = item
        p.font.size = Pt(18)
        p.level = 0
        p.space_before = Pt(12)
    
    return slide

def add_image_slide(prs, title, image_path, caption=""):
    """Add a slide with an image"""
    slide = prs.slides.add_slide(prs.slide_layouts[6])
    
    # Add title
    title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.5), Inches(9), Inches(0.8))
    title_frame = title_box.text_frame
    title_frame.text = title
    title_frame.paragraphs[0].font.size = Pt(32)
    title_frame.paragraphs[0].font.bold = True
    title_frame.paragraphs[0].font.color.rgb = RGBColor(31, 78, 121)
    
    # Add image if it exists
    if Path(image_path).exists():
        slide.shapes.add_picture(image_path, Inches(1.5), Inches(2), width=Inches(7))
        
        # Add caption if provided
        if caption:
            caption_box = slide.shapes.add_textbox(Inches(0.5), Inches(6.5), Inches(9), Inches(0.5))
            caption_frame = caption_box.text_frame
            caption_frame.text = caption
            caption_frame.paragraphs[0].font.size = Pt(14)
            caption_frame.paragraphs[0].alignment = PP_ALIGN.CENTER
    
    return slide

def add_table_slide(prs, title, data_dict):
    """Add a slide with a table"""
    slide = prs.slides.add_slide(prs.slide_layouts[6])
    
    # Add title
    title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.5), Inches(9), Inches(0.8))
    title_frame = title_box.text_frame
    title_frame.text = title
    title_frame.paragraphs[0].font.size = Pt(32)
    title_frame.paragraphs[0].font.bold = True
    title_frame.paragraphs[0].font.color.rgb = RGBColor(31, 78, 121)
    
    # Create table
    rows = len(data_dict['data']) + 1  # +1 for header
    cols = len(data_dict['headers'])
    
    table = slide.shapes.add_table(rows, cols, Inches(1), Inches(2), Inches(8), Inches(4)).table
    
    # Set column headers
    for col_idx, header in enumerate(data_dict['headers']):
        cell = table.cell(0, col_idx)
        cell.text = header
        cell.text_frame.paragraphs[0].font.bold = True
        cell.text_frame.paragraphs[0].font.size = Pt(16)
        cell.fill.solid()
        cell.fill.fore_color.rgb = RGBColor(31, 78, 121)
        cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(255, 255, 255)
    
    # Fill data
    for row_idx, row_data in enumerate(data_dict['data'], start=1):
        for col_idx, value in enumerate(row_data):
            cell = table.cell(row_idx, col_idx)
            cell.text = str(value)
            cell.text_frame.paragraphs[0].font.size = Pt(14)
    
    return slide

# ===== SLIDE 1: Title =====
add_title_slide(
    prs,
    "Analyse Automatique des Sentiments",
    "Projet NLP - Dataset Sentiment140"
)

# ===== SLIDE 2: Introduction =====
add_content_slide(
    prs,
    "ğŸ“‹ Introduction",
    [
        "ğŸ¯ Objectif: Classifier automatiquement les sentiments dans les tweets",
        "ğŸ“Š Dataset: Sentiment140 (1.6 million de tweets)",
        "âš–ï¸ Classes: Positif (ğŸ˜Š) vs NÃ©gatif (ğŸ˜)",
        "ğŸ› ï¸ Technologie: Python, Scikit-learn, NLTK, Pandas",
        "ğŸ“… PÃ©riode: Semaines 1-3 du planning projet"
    ]
)

# ===== SLIDE 3: Dataset Overview =====
add_content_slide(
    prs,
    "ğŸ“Š Dataset: Sentiment140",
    [
        "âœ“ Source: Stanford University (Twitter data)",
        "âœ“ Taille: 1,600,000 tweets",
        "âœ“ Distribution: 800K nÃ©gatifs (0) + 800K positifs (4)",
        "âœ“ Balance parfaite: 50% / 50%",
        "âœ“ Colonnes: target, text, user, date, ids",
        "âœ“ Fichier: 73.2 MB aprÃ¨s nettoyage",
        "âœ“ Ã‰chantillon utilisÃ©: 100,000 tweets (50K+50K)"
    ]
)

# ===== SLIDE 4: Semaine 1 - Exploration =====
add_content_slide(
    prs,
    "ğŸ” Semaine 1: Exploration Initiale",
    [
        "âœ“ TÃ©lÃ©chargement du dataset depuis Kaggle",
        "âœ“ Chargement avec encoding latin-1",
        "âœ“ Analyse de la structure des donnÃ©es",
        "âœ“ VÃ©rification des valeurs manquantes: 0",
        "âœ“ Statistiques textuelles:",
        "   â€¢ Longueur moyenne: 74 caractÃ¨res",
        "   â€¢ Nombre moyen de mots: 13 mots/tweet",
        "   â€¢ Distribution Ã©quilibrÃ©e confirmÃ©e"
    ]
)

# ===== SLIDE 5: Semaine 2 - PrÃ©traitement (1) =====
add_content_slide(
    prs,
    "ğŸ§¹ Semaine 2: PrÃ©traitement des DonnÃ©es",
    [
        "âœ“ Nettoyage du texte:",
        "   â€¢ Conversion en minuscules",
        "   â€¢ Suppression des URLs (http://, https://)",
        "   â€¢ Suppression des mentions (@user)",
        "   â€¢ Suppression des hashtags (#topic)",
        "   â€¢ Suppression des caractÃ¨res spÃ©ciaux et chiffres",
        "   â€¢ Normalisation des espaces",
        "âœ“ RÃ©sultat: texte propre prÃªt pour la modÃ©lisation"
    ]
)

# ===== SLIDE 6: Visualisations =====
add_content_slide(
    prs,
    "ğŸ“ˆ Visualisations - Analyses EffectuÃ©es",
    [
        "âœ“ Distribution des sentiments (bar chart + pie chart)",
        "âœ“ Histogrammes des longueurs de texte par sentiment",
        "âœ“ Distribution du nombre de mots par sentiment",
        "âœ“ Word Clouds pour nÃ©gatif et positif",
        "âœ“ Top 20 mots les plus frÃ©quents par sentiment",
        "âœ“ Toutes les visualisations sauvegardÃ©es en haute rÃ©solution"
    ]
)

# ===== SLIDE 7: Word Clouds =====
# Try to add word cloud image if it exists
wordcloud_path = "visuals/wordclouds/sentiment_wordclouds.png"
add_image_slide(
    prs,
    "â˜ï¸ Word Clouds: Mots FrÃ©quents",
    wordcloud_path,
    "Mots les plus frÃ©quents dans les tweets nÃ©gatifs (rouge) et positifs (vert)"
)

# ===== SLIDE 8: Semaine 3 - ML Models =====
add_content_slide(
    prs,
    "ğŸ¤– Semaine 3: ModÃ¨les ML Baseline",
    [
        "âœ“ Vectorisation: TF-IDF (10,000 features)",
        "   â€¢ Term Frequency - Inverse Document Frequency",
        "   â€¢ Unigrams + Bigrams (1-2 mots)",
        "   â€¢ min_df=5, max_df=0.7",
        "âœ“ Split: Train (80%) / Test (20%)",
        "   â€¢ Train: 79,788 tweets",
        "   â€¢ Test: 19,947 tweets",
        "âœ“ Stratification pour maintenir la balance"
    ]
)

# ===== SLIDE 9: 3 ModÃ¨les EntraÃ®nÃ©s =====
add_content_slide(
    prs,
    "ğŸ¯ ModÃ¨les ML ImplÃ©mentÃ©s",
    [
        "1ï¸âƒ£ Logistic Regression",
        "   â€¢ ModÃ¨le linÃ©aire simple et rapide",
        "   â€¢ Bon baseline pour classification binaire",
        "",
        "2ï¸âƒ£ Support Vector Machine (LinearSVC)",
        "   â€¢ Trouve le meilleur hyperplan de sÃ©paration",
        "   â€¢ Excellent pour classification de texte",
        "",
        "3ï¸âƒ£ Random Forest",
        "   â€¢ Ensemble de 100 arbres de dÃ©cision",
        "   â€¢ Capture les patterns non-linÃ©aires"
    ]
)

# ===== SLIDE 10: RÃ©sultats Comparatifs =====
results_data = {
    'headers': ['ModÃ¨le', 'Accuracy', 'Precision', 'Recall', 'F1-Score'],
    'data': [
        ['Logistic Regression', '79.19%', '0.7922', '0.7915', '0.7918'],
        ['SVM (LinearSVC)', '79.15%', '0.7918', '0.7912', '0.7915'],
        ['Random Forest', '77.24%', '0.7728', '0.7721', '0.7724']
    ]
}

add_table_slide(
    prs,
    "ğŸ“Š RÃ©sultats: Comparaison des ModÃ¨les",
    results_data
)

# ===== SLIDE 11: MÃ©triques ExpliquÃ©es =====
add_content_slide(
    prs,
    "ğŸ“ MÃ©triques d'Ã‰valuation",
    [
        "âœ“ Accuracy: Proportion de prÃ©dictions correctes",
        "   â€¢ (TP + TN) / Total",
        "",
        "âœ“ Precision: Parmi les prÃ©dictions positives, combien sont correctes",
        "   â€¢ TP / (TP + FP)",
        "",
        "âœ“ Recall: Parmi les vrais positifs, combien sont dÃ©tectÃ©s",
        "   â€¢ TP / (TP + FN)",
        "",
        "âœ“ F1-Score: Moyenne harmonique de Precision et Recall",
        "   â€¢ 2 Ã— (Precision Ã— Recall) / (Precision + Recall)"
    ]
)

# ===== SLIDE 12: Matrices de Confusion =====
add_content_slide(
    prs,
    "ğŸ¯ Matrices de Confusion",
    [
        "Analyse des erreurs pour chaque modÃ¨le:",
        "",
        "âœ“ True Positives (TP): Positifs correctement prÃ©dits",
        "âœ“ True Negatives (TN): NÃ©gatifs correctement prÃ©dits",
        "âœ“ False Positives (FP): NÃ©gatifs prÃ©dits comme positifs",
        "âœ“ False Negatives (FN): Positifs prÃ©dits comme nÃ©gatifs",
        "",
        "ğŸ“Š 3 matrices gÃ©nÃ©rÃ©es et sauvegardÃ©es",
        "ğŸ“ˆ ~79% de prÃ©cision globale"
    ]
)

# ===== SLIDE 13: Confusion Matrix Image =====
cm_path = "visuals/confusion_matrices/logistic_regression_cm.png"
add_image_slide(
    prs,
    "ğŸ“Š Matrice de Confusion - Logistic Regression",
    cm_path,
    "Meilleur modÃ¨le avec 79.19% d'accuracy"
)

# ===== SLIDE 14: Exemple de PrÃ©dictions =====
add_content_slide(
    prs,
    "âœ… Tests sur Exemples RÃ©els",
    [
        "Tweet: \"i love this product it is amazing\"",
        "â†’ PrÃ©diction: ğŸ˜Š POSITIVE âœ“",
        "",
        "Tweet: \"this is the worst experience ever\"",
        "â†’ PrÃ©diction: ğŸ˜ NEGATIVE âœ“",
        "",
        "Tweet: \"great quality highly recommend\"",
        "â†’ PrÃ©diction: ğŸ˜Š POSITIVE âœ“",
        "",
        "Tweet: \"waste of money do not buy\"",
        "â†’ PrÃ©diction: ğŸ˜ NEGATIVE âœ“"
    ]
)


# ===== SLIDE 16: Points ClÃ©s =====
add_content_slide(
    prs,
    "ğŸŒŸ Points ClÃ©s & RÃ©ussites",
    [
        "âœ… Dataset Ã©quilibrÃ©: pas de biais de classe",
        "âœ… PrÃ©traitement robuste: texte propre et normalisÃ©",
        "âœ… TF-IDF efficace: 10K features pertinentes",
        "âœ… 3 modÃ¨les ML implÃ©mentÃ©s et comparÃ©s",
        "âœ… 79% accuracy: bon rÃ©sultat pour un baseline",
        "âœ… Tous les modÃ¨les sauvegardÃ©s pour rÃ©utilisation",
        "âœ… Visualisations complÃ¨tes et professionnelles",
        "âœ… Code documentÃ© et reproductible"
    ]
)

# ===== SLIDE 17: Prochaines Ã‰tapes =====
add_content_slide(
    prs,
    "ğŸš€ Prochaines Ã‰tapes (Semaines 4-7)",
    [
        "ğŸ“… Semaine 4: Deep Learning",
        "   â€¢ RNN, LSTM, GRU pour capturer le contexte sÃ©quentiel",
        "",
        "ğŸ“… Semaine 5: Transfer Learning",
        "   â€¢ BERT fine-tuning pour amÃ©liorer les performances",
        "   â€¢ Hyperparameter tuning avec GridSearchCV",
        "",
        "ğŸ“… Semaine 6: Clustering",
        "   â€¢ Analyse non-supervisÃ©e (K-Means, DBSCAN)",
        "",
        "ğŸ“… Semaine 7: Finalisation",
        "   â€¢ Rapport final et prÃ©sentation"
    ]
)

# ===== SLIDE 18: Ce qui Reste Ã  Faire (Section 3.2) =====
add_content_slide(
    prs,
    "ğŸ“ Section 3.2 - Ã‰lÃ©ments Ã  ComplÃ©ter",
    [
        "Pour complÃ©ter la section 3.2 du cahier des charges:",
        "",
        "ğŸ”² Bag of Words (BoW) - Autre mÃ©thode de vectorisation",
        "ğŸ”² Word Embeddings (Word2Vec, GloVe)",
        "ğŸ”² GridSearchCV / RandomizedSearchCV",
        "   â€¢ Optimisation automatique des hyperparamÃ¨tres",
        "ğŸ”² AUC-ROC comme mÃ©trique supplÃ©mentaire",
        "ğŸ”² Analyse approfondie des erreurs",
        "   â€¢ Identifier les phrases difficiles Ã  classer",
        "",
        "â†’ PrÃ©vu dans Notebook 02B"
    ]
)

# ===== SLIDE 19: Technologies & Outils =====
add_content_slide(
    prs,
    "ğŸ› ï¸ Technologies UtilisÃ©es",
    [
        "ğŸ Python 3.11",
        "ğŸ““ Jupyter Notebook",
        "ğŸ“Š Pandas & NumPy (manipulation de donnÃ©es)",
        "ğŸ¤– Scikit-learn (modÃ¨les ML)",
        "ğŸ“ˆ Matplotlib & Seaborn (visualisations)",
        "ğŸ’¬ NLTK (traitement du langage naturel)",
        "â˜ï¸ WordCloud (nuages de mots)",
        "ğŸ’¾ Pickle (sauvegarde des modÃ¨les)",
        "ğŸ“ Git & GitHub (versioning)"
    ]
)

# ===== SLIDE 20: Conclusion =====
add_content_slide(
    prs,
    "ğŸ“ Conclusion",
    [
        "âœ… Semaines 1-3 complÃ©tÃ©es avec succÃ¨s",
        "",
        "ğŸ“Š Dataset explorÃ© et bien compris",
        "ğŸ§¹ PrÃ©traitement efficace et reproductible",
        "ğŸ¤– Baseline ML solide: 79% accuracy",
        "ğŸ“ˆ Visualisations claires et informatives",
        "",
        "ğŸ¯ Objectif atteint pour cette phase",
        "ğŸš€ PrÃªt pour les modÃ¨les Deep Learning",
        "",
        "ğŸ“– Code disponible sur GitHub",
        "ğŸ“§ Questions ?"
    ]
)

# ===== SLIDE 21: Merci =====
add_title_slide(
    prs,
    "Merci pour votre attention ! ğŸ™",
    "Questions ?"
)

# Save presentation
output_path = Path("reports/Presentation_Sentiment_Analysis.pptx")
output_path.parent.mkdir(parents=True, exist_ok=True)
prs.save(str(output_path))

print(f"âœ… PrÃ©sentation crÃ©Ã©e avec succÃ¨s !")
print(f"ğŸ“ Fichier: {output_path}")
print(f"ğŸ“Š Nombre de slides: {len(prs.slides)}")
print(f"\nğŸ¯ La prÃ©sentation contient:")
print(f"   â€¢ Slide de titre")
print(f"   â€¢ Introduction et objectifs")
print(f"   â€¢ Description du dataset")
print(f"   â€¢ Travail des semaines 1-3")
print(f"   â€¢ RÃ©sultats comparatifs des modÃ¨les")
print(f"   â€¢ Visualisations et matrices de confusion")
print(f"   â€¢ Prochaines Ã©tapes")
print(f"   â€¢ Technologies utilisÃ©es")
print(f"   â€¢ Conclusion")
