{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b82b5fa",
   "metadata": {},
   "source": [
    "# Unsupervised Learning: Clustering and Topic Modeling\n",
    "\n",
    "This notebook explores unsupervised learning techniques for sentiment analysis, including K-Means clustering, topic modeling with LDA, and dimensionality reduction with t-SNE visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464ba56d",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c35228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Clustering and dimensionality reduction\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import LatentDirichletAllocation, PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "# Feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Plotting\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.join('..', 'src'))\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540becaa",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0787c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "data_path = os.path.join('..', 'data', 'processed', 'cleaned_tweets.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Use a sample for faster computation\n",
    "SAMPLE_SIZE = 20000\n",
    "df_sample = df.sample(n=min(SAMPLE_SIZE, len(df)), random_state=42)\n",
    "\n",
    "print(f\"Dataset shape: {df_sample.shape}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df_sample['sentiment'].value_counts())\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06cdd01",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa7efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,  # Limit features for computational efficiency\n",
    "    max_df=0.8,\n",
    "    min_df=5,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df_sample['cleaned_text'])\n",
    "\n",
    "print(f\"TF-IDF feature matrix shape: {X_tfidf.shape}\")\n",
    "print(f\"Number of features: {len(tfidf_vectorizer.get_feature_names_out())}\")\n",
    "print(f\"Matrix sparsity: {(1 - X_tfidf.nnz / (X_tfidf.shape[0] * X_tfidf.shape[1])) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a10d3d",
   "metadata": {},
   "source": [
    "## 4. K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552765a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal number of clusters using elbow method\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "print(\"Finding optimal number of clusters...\")\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_tfidf)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_tfidf, kmeans.labels_))\n",
    "    print(f\"K={k}: Inertia={kmeans.inertia_:.2f}, Silhouette={silhouette_scores[-1]:.4f}\")\n",
    "\n",
    "# Plot elbow curve and silhouette scores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(K_range, inertias, marker='o', linewidth=2)\n",
    "axes[0].set_title('Elbow Method', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Number of Clusters (K)', fontsize=12)\n",
    "axes[0].set_ylabel('Inertia', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(K_range, silhouette_scores, marker='s', color='green', linewidth=2)\n",
    "axes[1].set_title('Silhouette Score', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Number of Clusters (K)', fontsize=12)\n",
    "axes[1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visuals/charts/kmeans_optimization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d45f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-Means with optimal K (trying K=2 since we have binary sentiment)\n",
    "optimal_k = 2\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_tfidf)\n",
    "\n",
    "# Add cluster labels to dataframe\n",
    "df_sample['cluster'] = clusters\n",
    "\n",
    "print(f\"\\nK-Means Clustering with K={optimal_k}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Silhouette Score: {silhouette_score(X_tfidf, clusters):.4f}\")\n",
    "print(f\"Davies-Bouldin Index: {davies_bouldin_score(X_tfidf.toarray(), clusters):.4f}\")\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_score(X_tfidf.toarray(), clusters):.4f}\")\n",
    "\n",
    "# Analyze clusters vs actual sentiment\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(df_sample['cluster'].value_counts())\n",
    "print(f\"\\nCluster vs Sentiment crosstab:\")\n",
    "print(pd.crosstab(df_sample['cluster'], df_sample['sentiment'], normalize='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeea644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top terms per cluster\n",
    "def get_top_terms_per_cluster(kmeans_model, vectorizer, n_terms=10):\n",
    "    \"\"\"\n",
    "    Get top terms for each cluster\n",
    "    \"\"\"\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    order_centroids = kmeans_model.cluster_centers_.argsort()[:, ::-1]\n",
    "    \n",
    "    for i in range(kmeans_model.n_clusters):\n",
    "        print(f\"\\nCluster {i} top terms:\")\n",
    "        top_terms = [terms[ind] for ind in order_centroids[i, :n_terms]]\n",
    "        print(\", \".join(top_terms))\n",
    "\n",
    "get_top_terms_per_cluster(kmeans, tfidf_vectorizer, n_terms=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e87014a",
   "metadata": {},
   "source": [
    "## 5. Topic Modeling with LDA (Latent Dirichlet Allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d208f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Count Vectorizer for LDA (LDA works with count data, not TF-IDF)\n",
    "count_vectorizer = CountVectorizer(\n",
    "    max_features=1000,\n",
    "    max_df=0.8,\n",
    "    min_df=5,\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_counts = count_vectorizer.fit_transform(df_sample['cleaned_text'])\n",
    "\n",
    "print(f\"Count matrix shape: {X_counts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8543e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model\n",
    "n_topics = 5\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics,\n",
    "    random_state=42,\n",
    "    max_iter=20,\n",
    "    learning_method='online',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"Training LDA with {n_topics} topics...\")\n",
    "lda.fit(X_counts)\n",
    "print(\"LDA training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f808bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top words for each topic\n",
    "def display_topics(model, feature_names, n_top_words=10):\n",
    "    \"\"\"\n",
    "    Display top words for each topic\n",
    "    \"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"\\nTopic {topic_idx}:\")\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        print(\", \".join(top_words))\n",
    "\n",
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "print(\"=\"*70)\n",
    "print(\"Topics discovered by LDA:\")\n",
    "print(\"=\"*70)\n",
    "display_topics(lda, feature_names, n_top_words=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9234ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic distribution for each document\n",
    "topic_distributions = lda.transform(X_counts)\n",
    "df_sample['dominant_topic'] = topic_distributions.argmax(axis=1)\n",
    "\n",
    "print(f\"\\nTopic distribution:\")\n",
    "print(df_sample['dominant_topic'].value_counts().sort_index())\n",
    "\n",
    "# Analyze topic vs sentiment\n",
    "print(f\"\\nTopic vs Sentiment crosstab:\")\n",
    "print(pd.crosstab(df_sample['dominant_topic'], df_sample['sentiment'], normalize='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292991d3",
   "metadata": {},
   "source": [
    "## 6. Dimensionality Reduction and Visualization with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5756545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First reduce dimensions with PCA for faster t-SNE\n",
    "print(\"Reducing dimensions with PCA...\")\n",
    "pca = PCA(n_components=50, random_state=42)\n",
    "X_pca = pca.fit_transform(X_tfidf.toarray())\n",
    "print(f\"PCA explained variance: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "\n",
    "# Apply t-SNE for 2D visualization\n",
    "print(\"\\nApplying t-SNE for 2D visualization (this may take a few minutes)...\")\n",
    "tsne_2d = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "X_tsne_2d = tsne_2d.fit_transform(X_pca)\n",
    "\n",
    "print(\"t-SNE 2D complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize t-SNE with actual sentiment labels\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot by sentiment\n",
    "scatter1 = axes[0].scatter(\n",
    "    X_tsne_2d[:, 0], X_tsne_2d[:, 1],\n",
    "    c=df_sample['sentiment'],\n",
    "    cmap='coolwarm',\n",
    "    alpha=0.6,\n",
    "    s=10\n",
    ")\n",
    "axes[0].set_title('t-SNE Visualization by Sentiment', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('t-SNE Component 1')\n",
    "axes[0].set_ylabel('t-SNE Component 2')\n",
    "cbar1 = plt.colorbar(scatter1, ax=axes[0])\n",
    "cbar1.set_label('Sentiment (0=Neg, 1=Pos)')\n",
    "\n",
    "# Plot by cluster\n",
    "scatter2 = axes[1].scatter(\n",
    "    X_tsne_2d[:, 0], X_tsne_2d[:, 1],\n",
    "    c=df_sample['cluster'],\n",
    "    cmap='viridis',\n",
    "    alpha=0.6,\n",
    "    s=10\n",
    ")\n",
    "axes[1].set_title('t-SNE Visualization by K-Means Cluster', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('t-SNE Component 1')\n",
    "axes[1].set_ylabel('t-SNE Component 2')\n",
    "cbar2 = plt.colorbar(scatter2, ax=axes[1])\n",
    "cbar2.set_label('Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visuals/charts/tsne_visualization_2d.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85649efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D t-SNE visualization\n",
    "print(\"Applying t-SNE for 3D visualization...\")\n",
    "tsne_3d = TSNE(n_components=3, random_state=42, perplexity=30, n_iter=1000)\n",
    "X_tsne_3d = tsne_3d.fit_transform(X_pca)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    X_tsne_3d[:, 0], X_tsne_3d[:, 1], X_tsne_3d[:, 2],\n",
    "    c=df_sample['sentiment'],\n",
    "    cmap='coolwarm',\n",
    "    alpha=0.6,\n",
    "    s=10\n",
    ")\n",
    "\n",
    "ax.set_title('3D t-SNE Visualization by Sentiment', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('t-SNE Component 1')\n",
    "ax.set_ylabel('t-SNE Component 2')\n",
    "ax.set_zlabel('t-SNE Component 3')\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax, pad=0.1)\n",
    "cbar.set_label('Sentiment (0=Neg, 1=Pos)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visuals/charts/tsne_visualization_3d.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"3D t-SNE complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5a20b",
   "metadata": {},
   "source": [
    "## 7. Summary and Insights\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **K-Means Clustering:**\n",
    "   - Discovered natural groupings in the data\n",
    "   - Analyzed how clusters align with true sentiment labels\n",
    "   - Examined characteristic terms for each cluster\n",
    "\n",
    "2. **Topic Modeling (LDA):**\n",
    "   - Identified latent topics in tweets\n",
    "   - Each topic represents a theme or subject area\n",
    "   - Topics may correlate with sentiment patterns\n",
    "\n",
    "3. **t-SNE Visualization:**\n",
    "   - Reduced high-dimensional TF-IDF features to 2D/3D\n",
    "   - Visualized data distribution and separation\n",
    "   - Observed clustering patterns visually\n",
    "   - 2D and 3D plots show how sentiments are distributed\n",
    "\n",
    "4. **Insights:**\n",
    "   - Unsupervised methods can discover patterns without labels\n",
    "   - Clusters may or may not align perfectly with sentiment\n",
    "   - Topic modeling reveals what people talk about\n",
    "   - Visualization helps understand data structure\n",
    "\n",
    "### Observations:\n",
    "- If clusters align well with sentiments → good separability in feature space\n",
    "- If topics show distinct sentiment patterns → topics carry sentiment information\n",
    "- t-SNE plots reveal if positive/negative tweets form distinct groups\n",
    "- These insights validate supervised model performance\n",
    "\n",
    "### Applications:\n",
    "- Discover emerging topics in social media\n",
    "- Identify customer pain points or satisfaction drivers\n",
    "- Explore data before labeling (semi-supervised learning)\n",
    "- Validate that sentiment classes are distinguishable"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
