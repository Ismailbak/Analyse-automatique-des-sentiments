# Sentiment140 NLP Project

Project scaffold for sentiment analysis on the Sentiment140 dataset. This repository contains datasets, notebooks, modular `src/` code, model storage, visualizations, and reports to support experimentation from preprocessing through model fine-tuning and evaluation.

## Project Structure

### ğŸ“ `data/`
- `raw/` â€” Original Sentiment140 dataset (sentiment140.csv)
- `processed/` â€” Cleaned tweets and preprocessed data (cleaned_tweets.csv, features_tfidf.pkl)
- `embeddings/` â€” Saved word embeddings (glove_vectors.pkl, bert_embeddings.pkl)

### ğŸ“ `notebooks/`
Jupyter notebooks for each project phase:
- `01_exploration_preprocessing.ipynb` â€” Data exploration and cleaning
- `02_ml_models_baselines.ipynb` â€” Logistic Regression, SVM, Random Forest
- `03_dl_lstm_gru.ipynb` â€” LSTM/GRU deep learning models
- `04_dl_bert_transfer_learning.ipynb` â€” BERT fine-tuning
- `05_clustering_unsupervised.ipynb` â€” K-Means, LDA, t-SNE
- `06_results_visualization.ipynb` â€” Final comparisons and charts

### ğŸ“ `src/`
Reusable Python modules:
- `data_loader.py` â€” Load and split datasets
- `text_cleaning.py` â€” Text preprocessing and tokenization
- `feature_engineering.py` â€” TF-IDF, embeddings, vectorizers
- `train_ml.py` â€” Train classical ML models
- `train_dl.py` â€” LSTM/GRU model builders
- `bert_finetuning.py` â€” BERT fine-tuning utilities
- `evaluation.py` â€” Metrics, confusion matrices, plots

### ğŸ“ `models/`
Saved model artifacts:
- `ml/` â€” Pickled ML models (logreg.pkl, svm.pkl, random_forest.pkl)
- `dl/` â€” Deep learning models (lstm_model.h5, bert_model/)
- `vectorizers/` â€” Saved vectorizers and tokenizers (tfidf_vectorizer.pkl, tokenizer.pkl)

### ğŸ“ `visuals/`
Generated visualizations:
- `wordclouds/` â€” Positive and negative word clouds
- `confusion_matrices/` â€” Confusion matrix plots for each model
- `charts/` â€” Accuracy, F1-score comparisons, t-SNE plots

### ğŸ“ `reports/`
Documentation and presentations:
- `Rapport_Sentiment140_NLP.pdf` â€” Final report (10â€“15 pages)
- `rapport_intermediaire_S3.pdf` â€” Intermediate report (3â€“4 pages)
- `presentation_slides.pptx` â€” Oral presentation

## Setup

Install dependencies:
```bash
pip install -r requirements.txt
```

See `requirements.txt` for core Python dependencies (scikit-learn, TensorFlow, PyTorch, Transformers, etc.).

